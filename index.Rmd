---
title: "Tutorial deforistation monitoring Peru"
author: "Rony Nedkov"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  knitrBootstrap::bootstrap_document:
    title: "Tutorial deforistation monitoring Peru"
    theme: cosmo
    menu: FALSE
---

#Tutorial deforistation monitoring Peru

## Introduction
The `bfastSpatial` package provides utilities to performs change detection analysis (see DeVries et al. 2015; Dutrieux et al. 2015; J. Verbesselt et al. 2010; J. Verbesselt, Zeileis, and Herold 2012) on time-series of spatial gridded data, such as time-series of remote sensing images (Landsat, MODIS and the likes). The tools provided by bfastSpatial allows a user to perform all the steps of the change detection workflow, from pre-processing raw surface reflectance Landsat data, inventorying and preparing them for analysis to the production and formatting of change detection results. The present document is an addition to the [bfast spatial tutorial](http://www.loicdutrieux.com/bfastSpatial/#Downloading_Landsat_data_from_Earth_Explorer_espa) in which the package will be used for deforistation monitoring based on Landsat scenes from Peru. 

In this tutorial the following change detection workflow steps will briefly discussed:

1. Downloading remote sensing scenes
2. Pre-processing the scenes
3. Spatial BFASTMonitor

###Setting up the working environment
Start with setting up your working environment. You want to make sure that we maintain a well structured project to prevent the loss or mixing up of data. In the script below we first load the `libraries` that we will be using. If you cannot load any packages then you most probably need to install it. Use `install.packages()` to do so. 

```{r, eval=FALSE, results='hide'}
#Loading packages
library(raster)
library(devtools)

#install and load bfastspatial from github
install_github('dutri001/bfastSpatial') #requires devtools
library(bfastSpatial)
```
We will set our working directory by specifying a `projectPath` which points to the folder where your project lives. We will create a `path5_row68` folder inside the `data` folder which we will use to save our initial data to. Set your working directory to the projectPath.

```{r, eval=FALSE, results='hide'}
#Set the working directory
projectPath <- "C:/../DeforestationPeru"
inputdata <- "data/path5_row68"
setwd(projectPath)
```

##1. Downloading Landsat data from Earth Explorer/espa
To download data from the [ESPA](https://espa.cr.usgs.gov/login/?next=/) website we first need to create a text file which contains the Landsat scene ID's of our area of interest. The common way to access the Landsat archives and retrieve the list is via the [Earth Explorer platform](http://earthexplorer.usgs.gov). You will need to register for an account.   

After logging in on the Earth Explorer platform you can search the Landsat archive by:

1. Defining the search criteria
2. Choosing data sets
3. Setting additional criteria
4. Exporting results

For this tutorial we will download scenes by specifying path and row numbers under the path/row tab. We want to find all scenes at **path number 5** and **row number 68**. Click the **show** button after entering the desired path and row number. A marker will appear on the map and this will make sure only scenes from that area will be downloaded. Set the date range from **1 January 2015 to the current date** to download all scenes that are available in that range. 

![define search criteria](figures/step_1_small.png)      

The second step is to select the data sets you wish to order under the Data Sets tab. For this tutorial we will use **Landsat Surface Reflectance - L8 OLI/TIRS** and **Landsat Surface Reflectance - L7 ETM+** from the **Landsat Archive**.

![define search criteria](figures/step_2.PNG)

In step three you can select additional criteria depending on your needs. The criterium we are interested in is the cloud cover. Setting this to **less than 80%** will filter out imagery that are completely covered by clouds. 

The final step is to export your results. In the results tab you can see a list of the scenes that have been found in the archive according to your search criteria. The meta-data of the scenes can be downloaded by clicking export results and specifying the output format. Choose **csv**. You will receive an email with a link where you can download the requested csv

###Placing order at ESPA
ESPA requires a list of scene ID's(eg: LT52302701999134) in a text file as input. We will create this list with an R script that automatically reads the csv, retrieves the ID's and saves them to a text file. 

First we want to read the csv in R and retrieve the scene ID's. We will also create the file in which we can save our output. 

```{r, results='hide'}
#read csv file
csv <- read.csv(file = "data/LSR_LANDSAT_8_97722_PATH5_ROW68.csv")

#Retrieve scene ID's from csv
sceneID <- as.character(csv$Landsat.Scene.Identifier)

#Create a text file
order_list <- file("orderlist.txt", "w")
```


Remember to change the `file` argument of `read.csv()` with the `"path/filename.csv"` pointing to the location of the csv on your own computer. The same goes for the output destination of `file()`.

To save each scene ID on a seperate line in the text file, we will use a loop that retrieves the scene ID's and adds them one by one to the text file with `writeLines()`. Close the connection to the file at the end to save your output. 


```{r, eval=FALSE, results='hide'}
#Retrieve the ID's from csv and write them on a new line in the file
for(i in 1:length(sceneID)) {
  ID <- sceneID[i]
  writeLines(ID, order_list, sep="\n")
}
#close connection to file
close(order_list)

```
The `sep="\n"` argument creates a new line after adding the ID to the text file. You can check the end result  of this script by opening your text file.

The final step requires Logging in to the [ESPA platform](https://espa.cr.usgs.gov/login/?next=/). Go to the order data page. Here you can upload the text file with the list of scenes you want to have pre-processed. Select the following options:

* CFMask (Cloud mask)
* Surface reflectance NDMI
* Geotiff 

Now you can submit your order.

### Downloading your data

You will receive an email when your order is ready for download. Use a download manager (e.g. Bulk Download Application or DownloadThemAll plugin for Firefox) to download all .tar.gz files and save them in a new subfolder in the `data` folder and name it `path5_row68`. 

##2. Pre-processing the Peru scenes

First step of the pre-processing is to run the `processLandsatBatch` method to extract the data and apply the cloud mask which is supplied with the data. 

```{r}{r, eval=FALSE, results='hide'}
# Create a temporary directory to store the output files.
srdir <- dirout <- file.path(dirname(rasterTmpFile()), 'bfmspatial')
dir.create(dirout, showWarning=FALSE)

# Get the directory where the Landsat archives are stored
list <- list.files(system.file("data/", package='bfastSpatial'), full.names=TRUE)

# Run the batch line
processLandsatBatch(x=list, vi='ndmi', outdir=dirout, srdir=srdir, delete=TRUE, mask='cfmask', keep=0, overwrite=TRUE, mc.cores = 4)
```

### Crop and mask

We are not interested in monitoring to complete area covered by the Landsat scenes. By cropping the scenes to the area of our interest we can reduce the processing time. The cropping is done based on the forestmask. This mask will also be used to mask the area of interest to identify the forest areas. 

```{r, eval=FALSE, results='hide'}
#Load the forest mask
fmask <- raster("data/forestmask/fm_potooccupa1.tif")

#retrieve scene names to add them back to the output rasters.             
dir <- list.files(dirout, pattern=glob2rx('*.grd'))

#Crop and mask the processed scenes and save them to disk
for (i in 1:length(list)) {
  scene <- raster(list[i])
  crop_scene <- extend(crop(scene, fmask), fmask)
  mask_scene <- mask(fmask, crop_scene)
  
  fname <- paste(dirout, "/fmask.", dir[i], sep = "")
  writeRaster(mask_scene, filename = fname, datatype = "INT2S", overwrite=TRUE)
}

```
the `for` loop runs through our list of processed ndmi images, crops the extent and masks the values according to the forestmask. `fname` is used to assign the correct file names for each output scene. 

### Create a multi-temporal raster object

Finally we need to create a mutli-temporal raster object by adding all processed rasters to a `rasterbrick` using the `timeStack` method. First we will create a new directory where we can save the stack. Then we can load the list with the masked Landsat scenes which we will use as the input for the `timeStack`.

```{r, eval=FALSE, results='hide'}
# Create a new subdirectory in the temporary directory
dirout <- file.path(dirname(rasterTmpFile()), 'stack')
dir.create(dirout, showWarnings=FALSE)

#List the masked Landsat scenes
list <- list.files(dirout, pattern=glob2rx('fmask*.grd'), full.names = TRUE)

# Generate a file name for the output stack
stackName <- file.path(dirout, 'stack.grd')

# Stack the layers
s <- timeStack(x=list, filename=stackName, datatype='INT2S', overwrite=TRUE)
```

##3. Spatial BFASTMonitor

